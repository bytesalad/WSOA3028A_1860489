Title: Ethical Concerns of Machine Learning and Computer Vision.

Subtitle: Linking @jeremyphoward's tweet [1] to "Computer Vision Machine Learning and Future-Oriented Ethics" by Abagayle L. Blank [2]

Published: 25 June 2020
By Matthew Brown

Introduction:

[tweet.jpg]

In his tweet [1], Jeremy Howard responds to a prominent AI researcher's decision to quit his research because of "ethical concerns". In my blog, I expand
on these ethical concerns and relate this tweet to a research paper called "Computer Vision Machine Learning and Future-Oriented Ethics" by Abagayle L. Blank 
[2]. Let's get straight into it.

Body:

Heading: What is Artificial Intelligence, Machine Learning, and Computer Vision?

In the paper [2], Artificial Intelligence is defined as "a growing resource of interactive, autonomous, self-learning agency, which enables computational
artifacts to perform tasks that otherwise would require human intelligence to be executed successfully". Computer vision is a subset of AI engineering that 
allows computers to be able to "see" events in the real world or perceive distinct details in an image. The leading technology to enable this is called 
Computer Vision Machine Learning (CVML). It is a special application of machine learning. The applications for computer vision can be facial recognition and 
self-driving cars.

[neural-network.png]
Image by <a href="https://pixabay.com/users/GDJ-1086657/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3816319">Gordon Johnson</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3816319">Pixabay</a>

Heading: Ethical Concerns.

In Blank's paper [2], several concerns for the use and implementation of CVML are outlined such as a competitive attitude between countries, consistent 
communication between governments and independent tech companies who implement these technologies and how well general society understands this 
technology and its implications.

The question we are always drawn to asking about this new technology is whether or not it can be entrusted with major decisions (political, medical, or 
humanitarian). Alongside technological advances is a story of competition between companies and even countries. During WW2 and the cold war, a period of 
rapid technological innovation took place but it was not without often terrifyingly competitive games between several countries [3]. Internet technologies 
have had a similar experience and still do as browser and operating system developers are constantly fighting for commercial dominance [4].

[arms-race.jpg]
David Simonds | The Times

CVML has its competitive drivers and several countries around the world are working to develop the best CVML technologies. Not only the best technologies 
but new ways to apply them. Often political. Even if this technology is possible, is it a good idea? Have a look at my blog on "4IR" for another look at 
emerging technologies and their implications (cite).

CVML could have adverse humanitarian complications when implemented incorrectly. This is explained at length in Blank's paper [2]. To summarise, this AI 
technology deals with a person's identity and how they are recognised and used. This kind of technology will need to be controlled in its manner of use 
and governments will need to work closely with tech companies and society at large to coordinate the use of this technology. Transparency is key and 
consumers, NGOs and academics should be allowed to collaborate.

In the paper [2], it is also explained that this new technology can be put to good use. In New Delhi, authorities used CVML to find 3000 missing children. It 
can also be used to diagnose rare genetic diseases and to implement cardless ATM services.

We must also realise that it is not perfect and is not a "one-shoe-fits-all" technology. This is reinforced by an article at theverge.com [5]. It was found 
that an upscaler machine learning tool will not work if they are very biased. The example in the article turns a low-resolution picture of a person of colour 
into a high-resolution picture of a person of white resemblance. A key success factor for these CVML technologies is to keep its training data as free from 
biases as possible. It must be noted that this is not easily done.

[upscaler.jpg]
https://twitter.com/Chicken3gg/status/1274314622447820801

Heading: Conclusion

Blank's paper [2] makes it very clear that the concerns raised in Jeremy's tweet [1] are not trivial and we are to be very interested in how machine 
learning technology is and will be applied. It has the power to affect everyone's lives. Hopefully for the better.

References:
[1] J. Howard. [@jeremyphoward], This is huge. The creator of the YOLO algorithms, which (along with SSD) set much of the path of modern object detection, has 
stopped doing any computer vision research due to ethical concerns. I've never seen anything quite like this before., Twitter,  Feb. 20, 2020 [Online]. Available: https://twitter.com/jeremyphoward/status/1230610470991589376 

[2] Abagayle Lee Blank. “Computer Vision Machine Learning and Future-Oriented Ethics”. In: (2019).
link: https://digitalcommons.spu.edu/honorsprojects/107/

[3] "Arms Race", HISTORY, 2020. [Online]. Available: https://www.history.com/topics/cold-war/arms-race. [Accessed: 28- Jun- 2020].
link: https://www.history.com/topics/cold-war/arms-race

[4] V. blogs, "The History of Browser Wars: The Mosaic, Netscape, and Microsoft", Web Solutions Blog, 2020. [Online]. Available: https://acodez.in/browser-wars/. [Accessed: 28- Jun- 2020].

[5] "What a machine learning tool that turns Obama white can (and can’t) tell us about AI bias", The Verge, 2020. [Online]. Available: https://www.theverge.com/21298762/face-depixelizer-ai-machine-learning-tool-pulse-stylegan-obama-bias. [Accessed: 28- Jun- 2020].
Link: https://www.theverge.com/21298762/face-depixelizer-ai-machine-learning-tool-pulse-stylegan-obama-bias